# Changelog

## [0.1.0](https://github.com/doublewordai/inference-lab/releases/tag/v0.1.0) (2025-12-05)

### Features

* Initial release of Inference Lab
* High-performance LLM inference simulator
* Support for multiple scheduling policies (FCFS, Priority, SJF)
* Chunked prefill simulation
* KV cache management
* Workload generation (Poisson, Gamma, closed-loop)
* WebAssembly support for browser usage
* CLI tool for command-line simulation
* Published to crates.io and npm
